# ===================================================================
# TRAP Configuration (Phase 1: Training, Phase 2: LoRA, Phase 3: Testing)
# ===================================================================

# Device configuration
device:
  cuda_id: 1  # CUDA device ID (0, 1, 2, etc.)
  num_workers: 24  # DataLoader workers (adjust based on CPU cores)

# Data configuration
data:
  # Phase 1: ImageNet data for model training (clean images only)
  imagenet:
    path: /data/ImageNet/train  # Path to ImageNet training data
    num_samples: -1  # Number of samples to use for training (-1 for all)
    batch_size: 512  # Batch size for training
    num_epochs: 1  # Number of training epochs

  # Phase 2: Domain-specific clean images for optional LoRA adaptation
  domain:
    clean_path: /data/coco/train2017  # Path to clean images of target domain
    num_samples: -1  # Number of clean samples (-1 for all available)
    batch_size: 512  # Batch size for adaptation
    num_epochs: 3  # Number of adaptation epochs

  # Phase 3: Test images (with potential patches)
  test:
    patch_path: /home/junesang/patch/patch_dataset/evaluation  # Path to test images
    num_samples: -1  # -1 = 전체 사용, 양수 = 해당 개수만 사용
    batch_size: 1024  # Batch size for testing

# Model configuration
model:
  # Backbone architecture for feature extraction
  # Options: resnet18, resnet34, resnet50, resnet101, resnet152,
  #          convnext_tiny, convnext_small, convnext_base,
  #          mobilenet_v3_small, mobilenet_v3_large,
  #          efficientnet_b0, efficientnet_b4,
  #          vit_b_16, vit_b_32, vit_l_16, vit_l_32, vit_h_14,
  #          deit_tiny_patch16_224, deit_small_patch16_224,
  #          deit_base_patch16_224, deit_base_patch16_384,
  #          swin_t, swin_s, swin_b, swin_v2_t, swin_v2_s, swin_v2_b
  backbone: swin_b  # Default: ResNet-50

  # Feature extraction settings
  spatial_resolution: 14  # Spatial resolution for feature extraction (7, 14, 28, 56)
  feature_dim: 128  # Feature dimension after channel pooling

  # Trajectory processing options
  trajectory:
    normalize_steps: true  # Apply per-layer z-score normalization
    normalization_eps: 1.0e-6  # Epsilon for normalization stability
    depth_scaling:
      enabled: false  # Scale features by layer depth (positional scalar)
      start: 0.8  # Scale factor for earliest layer
      end: 1.2  # Scale factor for deepest layer

  # Model architecture selection: 'autoencoder', 'vae', 'tcn_autoencoder', 'tcn_vae', 'transformer'
  type: tcn_vae  # Choose time-series anomaly detection model

  # Model hyperparameters
  hidden_dim: 128  # Hidden dimension for model
  latent_dim: 64  # Latent dimension (for autoencoder/vae)
  num_layers: 4  # Number of layers
  num_heads: 4  # Number of attention heads (for transformer only)
  dropout: 0.1  # Dropout rate (for transformer)
  tcn_kernel_size: 3  # Kernel size for temporal conv models (odd number recommended)
  tcn_dilation_base: 2  # Dilation growth factor for temporal conv models
  tcn_dropout: 0.1  # Dropout inside temporal conv blocks

  # Training settings
  optimizer: adamw  # Optimizer type ('adam', 'adamw', etc.)
  learning_rate: 0.003  # Learning rate for Phase 1 training
  weight_decay: 0.0001  # Weight decay (L2 regularization)
  vae_beta_max: 0.001  # Target beta weight for VAE KL term
  vae_beta_warmup_steps: 100000  # Warmup steps for beta annealing

  # Weight management for Phase 1 (Base Model)
  phase1:
    save_weights: true  # Save trained model weights
    load_weights: true  # Load pre-trained weights if available
    weights_dir: model_weights  # Directory to save/load weights
    # weights_path is auto-generated based on model config

# Domain Adaptation configuration (Phase 2)
domain_adaptation:
  enabled: false  # Enable/disable domain adaptation with LoRA

  # LoRA settings
  lora:
    rank: 8  # LoRA rank (lower = fewer parameters, faster training)
    alpha: 16  # LoRA scaling factor
    target_modules: ['Linear', 'Conv1d']  # Module types to adapt
    optimizer: adamw  # Optimizer for LoRA training
    learning_rate: 1e-4  # Lower learning rate for fine-tuning
    weight_decay: 1e-3  # Weight decay

  # Weight management for Phase 2 (LoRA Adaptation)
  phase2:
    save_weights: true  # Save LoRA adaptation weights
    load_weights: true  # Load pre-trained LoRA weights if available
    weights_dir: lora_weights  # Directory to save/load LoRA weights
    # weights_path is auto-generated based on model config

# Detection configuration
detection:
  # Threshold method for anomaly scores: 'mean_std', 'median_mad', 'percentile'
  threshold_method: mean_std

  # Parameters for 'mean_std' method
  threshold_multiplier: 3.0  # Threshold = mean + k*std

  # Parameters for 'median_mad' method (robust to outliers)
  mad_multiplier: 3.0  # Threshold = median + c*MAD

  # Parameters for 'percentile' method
  percentile: 95.0  # Use this percentile as threshold

  # Pixel-level detection threshold
  detection_pixel_threshold: 0  # Minimum number of anomalous pixels to classify as detected

# Evaluation configuration
evaluation:
  enable_patch_metrics: true  # Enable evaluation against patch metadata
  patch_metadata_path: /home/junesang/patch/patch_dataset/evaluation/evaluation_metadata.json  # Path to patch metadata JSON

  # Evaluation mode (noise type to evaluate)
  # Options: "silent" (no noise), "gaussian", "shot", "impulse"
  # When using generator.py datasets, this determines which noise variant to test
  mode: "silent"  # Default: no noise


# Output configuration
output:
  dir: detection_results  # Directory to save detection results
  save_visualizations: true  # Whether to save visualization images

# Experiment Tracking
experiment:
  use_wandb: true  # Enable Weights & Biases logging
  wandb_project: TRAP  # W&B project name
  wandb_entity: medicalissues  # W&B entity (username/team), null = default
