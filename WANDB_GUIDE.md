# Weights & Biases (wandb) í†µí•© ê°€ì´ë“œ

## ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” ì‹¤í—˜ ì¶”ì ì„ ìœ„í•´ **Weights & Biases (wandb)**ë¥¼ í†µí•©í–ˆìŠµë‹ˆë‹¤.
- âœ… **tqdm** ì§„í–‰ í‘œì‹œì¤„ë¡œ ì‹¤ì‹œê°„ í•™ìŠµ ì§„í–‰ ìƒí™© í™•ì¸
- âœ… **wandb** ë¡œ loss, hyperparameters ë“±ì„ ìë™ ë¡œê¹…
- âœ… ì„ íƒì  ì‚¬ìš©: configì—ì„œ ì‰½ê²Œ í™œì„±í™”/ë¹„í™œì„±í™”

## ì„¤ì¹˜

```bash
# tqdmê³¼ wandb ì„¤ì¹˜
pip install tqdm wandb

# ë˜ëŠ” requirements.txtë¡œ ì¼ê´„ ì„¤ì¹˜
pip install -r requirements.txt
```

## Wandb ì„¤ì •

### 1. Wandb ê³„ì • ìƒì„± ë° ë¡œê·¸ì¸

```bash
# wandb ë¡œê·¸ì¸ (ìµœì´ˆ 1íšŒë§Œ)
wandb login

# API í‚¤ ì…ë ¥ (https://wandb.ai/authorize ì—ì„œ í™•ì¸)
```

### 2. Config íŒŒì¼ì—ì„œ í™œì„±í™”

```yaml
# configs/config.yaml
experiment:
  use_wandb: true  # wandb í™œì„±í™”
  wandb_project: patch-detection  # í”„ë¡œì íŠ¸ ì´ë¦„
  wandb_entity: your-username  # íŒ€/ì‚¬ìš©ì ì´ë¦„ (ì„ íƒ)
```

### 3. ì»¤ë§¨ë“œ ë¼ì¸ì—ì„œ í™œì„±í™”

```bash
# wandb ì‚¬ìš©
python test.py experiment.use_wandb=true

# í”„ë¡œì íŠ¸ ì´ë¦„ ë³€ê²½
python test.py experiment.use_wandb=true experiment.wandb_project=my-project

# ì—”í‹°í‹° ì§€ì •
python test.py experiment.use_wandb=true experiment.wandb_entity=my-team
```

## ë¡œê¹…ë˜ëŠ” ì •ë³´

### Phase 1: ëª¨ë¸ í•™ìŠµ

**Metrics:**
- `epoch`: í˜„ì¬ ì—í­ ë²ˆí˜¸
- `train_loss`: ì—í­ í‰ê·  í•™ìŠµ loss

**Config (ìë™ ê¸°ë¡):**
- `model_type`: ëª¨ë¸ íƒ€ì… (autoencoder/vae/transformer)
- `num_epochs`: ì´ ì—í­ ìˆ˜
- `hidden_dim`: ì€ë‹‰ì¸µ ì°¨ì›
- `latent_dim`: ì ì¬ ê³µê°„ ì°¨ì›

**Run Name:** `train-{model_type}` (ì˜ˆ: `train-autoencoder`)

### Phase 2: LoRA ë„ë©”ì¸ ì ì‘

**Metrics:**
- `epoch`: í˜„ì¬ ì—í­ ë²ˆí˜¸
- `lora_loss`: ì—í­ í‰ê·  LoRA loss

**Config (ìë™ ê¸°ë¡):**
- `model_type`: ëª¨ë¸ íƒ€ì…
- `num_epochs`: ì´ ì—í­ ìˆ˜
- `lora_rank`: LoRA rank
- `lora_alpha`: LoRA alpha
- `lora_lr`: LoRA learning rate

**Run Name:** `lora-{model_type}` (ì˜ˆ: `lora-autoencoder`)

## ì‚¬ìš© ì˜ˆì œ

### ì˜ˆì œ 1: ê¸°ë³¸ ì‚¬ìš© (wandb ë¹„í™œì„±í™”)

```bash
# wandb ì—†ì´ ì‹¤í–‰ (ê¸°ë³¸ê°’)
python test.py
```

ì¶œë ¥:
```
[Phase 1: Model Training (Streaming)]
Training autoencoder in streaming mode...
Epochs: 10
  Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00, loss=0.0234]
    Epoch 1/10: Loss = 0.023456
```

### ì˜ˆì œ 2: wandb í™œì„±í™”

```bash
# wandb í™œì„±í™”
python test.py experiment.use_wandb=true
```

ì¶œë ¥:
```
[Phase 1: Model Training (Streaming)]
Training autoencoder in streaming mode...
Epochs: 10
wandb: Tracking run with wandb version 0.16.0
wandb: Run data is saved locally in ./wandb/run-20231215_123456
wandb: Run `wandb sync` to sync local data to cloud
wandb: View run at https://wandb.ai/your-user/patch-detection/runs/abc123
  Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00, loss=0.0234]
    Epoch 1/10: Loss = 0.023456
```

### ì˜ˆì œ 3: ì»¤ìŠ¤í…€ í”„ë¡œì íŠ¸

```bash
# ë‹¤ë¥¸ í”„ë¡œì íŠ¸ë¡œ ë¡œê¹…
python test.py \
  experiment.use_wandb=true \
  experiment.wandb_project=my-experiment \
  experiment.wandb_entity=my-team
```

### ì˜ˆì œ 4: ì—¬ëŸ¬ ëª¨ë¸ ë¹„êµ

```bash
# Autoencoder ì‹¤í—˜
python test.py \
  model.type=autoencoder \
  experiment.use_wandb=true

# VAE ì‹¤í—˜  
python test.py \
  model.type=vae \
  experiment.use_wandb=true

# Transformer ì‹¤í—˜
python test.py \
  model.type=transformer \
  experiment.use_wandb=true
```

Wandb ëŒ€ì‹œë³´ë“œì—ì„œ ì„¸ ì‹¤í—˜ì„ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

## tqdm ì§„í–‰ í‘œì‹œì¤„

Wandbì™€ ë³„ë„ë¡œ, **tqdm**ì´ í•­ìƒ í™œì„±í™”ë˜ì–´ ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•©ë‹ˆë‹¤:

```
[Phase 1: Model Training (Streaming)]
  Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00, loss=0.0234]
  Epoch 2/10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ      | 6/8 [00:01<00:00, loss=0.0198]
```

**í‘œì‹œ ì •ë³´:**
- ì§„í–‰ë¥  (%)
- ì§„í–‰ë°”
- í˜„ì¬/ì „ì²´ ë°°ì¹˜ ìˆ˜
- ê²½ê³¼ ì‹œê°„
- ì˜ˆìƒ ë‚¨ì€ ì‹œê°„
- í˜„ì¬ ë°°ì¹˜ì˜ loss

## Wandb ëŒ€ì‹œë³´ë“œ í™œìš©

### 1. Loss ê·¸ë˜í”„

ë¸Œë¼ìš°ì €ì—ì„œ ìë™ìœ¼ë¡œ ìƒì„±ë˜ëŠ” loss ê·¸ë˜í”„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- Xì¶•: epoch
- Yì¶•: train_loss / lora_loss

### 2. ì—¬ëŸ¬ ì‹¤í—˜ ë¹„êµ

ê°™ì€ í”„ë¡œì íŠ¸ì˜ ì—¬ëŸ¬ runì„ ì„ íƒí•˜ì—¬ ë¹„êµ:
- ë‹¤ë¥¸ ëª¨ë¸ íƒ€ì… ë¹„êµ
- ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¹„êµ
- í•™ìŠµ ì¶”ì´ ë¹„êµ

### 3. Config ì¶”ì 

ê° ì‹¤í—˜ì˜ ëª¨ë“  ì„¤ì •ì´ ìë™ìœ¼ë¡œ ê¸°ë¡ë©ë‹ˆë‹¤:
- ëª¨ë¸ êµ¬ì¡°
- í•™ìŠµ ì„¤ì •
- ë°ì´í„° ì„¤ì •

### 4. ì‹¤í—˜ ë…¸íŠ¸

Wandb ì›¹ì—ì„œ ê° ì‹¤í—˜ì— ë©”ëª¨ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### wandb ë¯¸ì„¤ì¹˜ ì‹œ

```python
Warning: wandb not installed, skipping logging
```

í•´ê²°:
```bash
pip install wandb
```

### ë¡œê·¸ì¸ ì•ˆë¨

```python
wandb: ERROR Not authenticated
```

í•´ê²°:
```bash
wandb login
```

### í”„ë¡œì íŠ¸ ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ

```python
wandb: ERROR Permission denied
```

í•´ê²°:
- `wandb_entity` ì„¤ì • í™•ì¸
- í”„ë¡œì íŠ¸ ê¶Œí•œ í™•ì¸

## ì˜¤í”„ë¼ì¸ ëª¨ë“œ

ì¸í„°ë„· ì—°ê²° ì—†ì´ ë¡œì»¬ì—ì„œë§Œ ë¡œê¹…:

```bash
# í™˜ê²½ ë³€ìˆ˜ë¡œ ì˜¤í”„ë¼ì¸ ì„¤ì •
export WANDB_MODE=offline
python test.py experiment.use_wandb=true

# ë‚˜ì¤‘ì— ë™ê¸°í™”
wandb sync ./wandb/run-*
```

## Best Practices

### 1. í”„ë¡œì íŠ¸ ì´ë¦„ ê·œì¹™

```yaml
experiment:
  wandb_project: patch-detection-v2  # ë²„ì „ ëª…ì‹œ
```

### 2. Run ì´ë¦„ ê·œì¹™

ìë™ ìƒì„±ë˜ëŠ” run ì´ë¦„:
- Phase 1: `train-{model_type}`
- Phase 2: `lora-{model_type}`

### 3. íƒœê·¸ ì¶”ê°€ (ì„ íƒ)

ì½”ë“œì—ì„œ ì»¤ìŠ¤í…€ íƒœê·¸ ì¶”ê°€ ê°€ëŠ¥:
```python
wandb.init(
    project='patch-detection',
    tags=['baseline', 'autoencoder', 'imagenet-1k']
)
```

### 4. ì‹¤í—˜ ê·¸ë£¹í™”

ê´€ë ¨ ì‹¤í—˜ì„ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ê¸°:
```python
wandb.init(
    project='patch-detection',
    group='model-comparison',
    job_type='train'
)
```

## ê²°ë¡ 

âœ… **tqdm + wandb** í†µí•©ìœ¼ë¡œ:
- ì‹¤ì‹œê°„ í•™ìŠµ ì§„í–‰ ìƒí™© í™•ì¸ (tqdm)
- ìë™ ì‹¤í—˜ ì¶”ì  ë° ë¹„êµ (wandb)
- ì„ íƒì  ì‚¬ìš© (configì—ì„œ on/off)
- ì¶”ê°€ ì½”ë“œ ë³€ê²½ ì—†ì´ ì‚¬ìš© ê°€ëŠ¥

Happy experimenting! ğŸš€
